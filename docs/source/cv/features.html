Feature Detection and Correspondance
====================================

In this section we explain how feature points are detected and matched
between different camera frames. The common feature detection and matching
pipeline for localization and mapping algorithms is:

* Detect regions of interests (image feature) in the image
* Extract image feature information using descriptors
* Match extracted descriptors



FAST
----

Feature detection in computer vision is a process of gathering scene
information and deciding locally whether an image feature exists. The resulting
subset of image features in the image domain can in turn be used for
localization and mapping algorithms to estimate the camera pose.

For our requirements corners was the chosen image feature. The most widely used
corner detector is the FAST feature detector~\cite{Rosten2006}. The advantage
of using FAST includes its speed and high detection rate. It operates by
inspecting a gray-scale image and applying a Bresenham circle or patch of
configurable radius (radius of 3 for a 16 pixel circle in
Fig~\ref{fig:fast_corner}), where each pixel value on the circle is labeled
clockwise. If a set of $N$ contiguous pixels in the circle are all brighter
than the intensity of the center candidate pixel $p$ plus a threshold value
$t$, or are all darker compared to $p$ minus a threshold value $t$, then $p$ is
considered a corner.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\linewidth]{images/feature/fast.jpg}
  \caption{FAST Corner Detection~\cite{Rosten2006}}
  \label{fig:fast_corner}
\end{figure}

% A uniform feature distribution over the image domain is known to avoid
% degenerate configurations for SLAM, and reduce redundant information. Further,
% a uniform and un-clustered corner distribution has the potential of increasing
% computer vision pipeline efficiency, as a lower number of features are required
% for the whole image. To encourage a uniform feature distribution a custom naive
% implementation of Grid-FAST was implemented~\footnote{At the time of writing
% OpenCV has removed the interface to the \texttt{GridAdaptedFeatureDetector}
% implementation from their code base.}. The naive Grid-FAST was implemented as
% follows, given an image we divide the image into $r$ rows and $c$ columns with
% the goal of detecting a total max number of $N$ corners. The max number of
% corners per grid cell $n$ is then given as
% %
% \begin{equation}
% n = \dfrac{N}{r \times c}.
% \end{equation}
% %
% Using $n$ we limit the corners detected in each image grid cell to naively
% encourage a uniform distribution.
%
% \begin{figure}[H]
%   \centering
%   \begin{subfigure}{0.47\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{images/background/fast.png}
%     \caption{FAST Detection (1000 Corners)}
%   \end{subfigure}
%   \hspace{0.5em}
%   \begin{subfigure}{0.47\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{images/background/grid_fast.png}
%     \caption{Grid-FAST Detection (714 Corners)}
%   \end{subfigure} \\ \vspace{1.0em}
%   \begin{subfigure}{0.485\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{images/background/fast_hist2d.png}
%     \caption{2D Histogram of FAST Detection}
%     \label{subfig:fast_hist2d}
%   \end{subfigure}
%   \hspace{0.3em}
%   \begin{subfigure}{0.485\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{images/background/grid_fast_hist2d.png}
%     \caption{2D Histogram of Grid-FAST Detection}
%     \label{subfig:grid_fast_hist2d}
%   \end{subfigure}
%   \caption{Comparison between FAST and Grid-FAST}
%   \label{fig:grid_fast_comparison}
% \end{figure}
%
% In Fig.~\ref{fig:grid_fast_comparison} both FAST and Grid-FAST observe the same
% image scene with the same detection parameters. Grid-FAST divided the image
% into 10 rows and columns to encourage a uniform corner detection. While
% Grid-FAST detected a lower number of corners compared to FAST (714, 1000
% respectively), we can observe the benefit of using Grid-FAST in
% Fig.~\ref{subfig:fast_hist2d} and Fig.~\ref{subfig:grid_fast_hist2d}, where it
% clearly shows that FAST detection has an undesirably high detection
% concentration around the chessboard in this particular scene, Grid-FAST on the
% other hand does not exhibit the same problem. Although, Grid-FAST obtains
% features of lower quality in terms of repeatable detection, the threshold of
% corner-ness can be increased if this is an issue.


Feature Descriptor
------------------

To correspond image features detected in two different image frames a feature
descriptor is used. Feature descriptors are a way to describe the image feature
observed for matching. There are a number of feature descriptors that extract
patch information in order to create a robust and repeatable match. Feature
descriptors such as SIFT~\cite{Lowe1999}, SURF~\cite{Bay2006}, are histogram of
gradients (HOG) based patch descriptors. These HOG descriptors are invariant to
small rotations and lighting variations, they are however, relatively expensive
to compute. The computationally expensive components are its calculation of the
image gradient and large descriptor dimension. While both descriptors provide
quality information of image features, the aforementioned computational factors
impact the matching speed significantly.

Binary descriptors such as BRIEF~\cite{Calonder2010}, ORB~\cite{Rublee2011} and
BRISK~\cite{Leutenegger2011} have been proposed to speed up the feature
descriptor and matching process. The performance boost in binary descriptors
comes in the form of using a binary sampling pattern around each image feature
previously detected (see Fig~\ref{fig:binary_descriptors}), and outputting a
binary vector, instead of computing image gradients and outputting a floating
point vector. Each binary descriptor uses its own unique sampling pattern, and
outputs a binary string to be used for matching. The matching process is
cheaper compared to the HOG based descriptors, because instead of comparing two
floating point vectors, comparing binary descriptors is performed by computing
the Hamming distance using a XOR or bit count operation, which can be performed
extremely quickly on modern CPUs~\cite{Calonder2012}.

\begin{figure}[htp]
  \centering
  \begin{subfigure}[t]{0.31\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/feature/brief.png}
    \caption{BRIEF Descriptor~\cite{Calonder2012}}
  \end{subfigure}
  \begin{subfigure}[t]{0.33\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/feature/orb.png}
    \caption{ORB Descriptor~\cite{Rublee2011}}
  \end{subfigure}
  \begin{subfigure}[t]{0.31\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/feature/brisk.png}
    \caption{BRISK Descriptor~\cite{Leutenegger2011}}
  \end{subfigure}
  \caption{Binary Descriptors}
  \label{fig:binary_descriptors}
\end{figure}

% \begin{figure}[htp]
% 	\centering
% 	\begin{subfigure}[t]{0.45\textwidth}
% 		\centering
% 		\includegraphics[width=\linewidth]{images/background/orb_matches1.png}
% 	\end{subfigure}
% 	\hspace{1.0em}
% 	\begin{subfigure}[t]{0.45\textwidth}
% 		\centering
% 		\includegraphics[width=\linewidth]{images/background/orb_matches2.png}
% 	\end{subfigure}
% 	\caption{ORB descriptors detecting features in the EuRoC MAV dataset~\cite{Burri2016}}
% 	\label{fig:orb_descriptors_in_action}
% \end{figure}
