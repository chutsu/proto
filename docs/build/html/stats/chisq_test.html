
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Pearson’s Chi-Squared Test &#8212; proto alpha documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"Vec": ["\\mathbf{#1}", 1], "Mat": ["\\mathbf{#1}", 1], "real": "\\rm I\\!R", "Real": ["{\\real^{#1}}", 1], "ones": "{\\Vec{1}}", "Ones": ["{\\Vec{1}_{#1\\times#2}}", 2], "zeros": "{\\Vec{0}}", "Zeros": ["{\\Vec{0}_{#1\\times#2}}", 2], "Norm": ["{\\left\\lVert{#1}\\right\\rVert}", 1], "Det": ["{\\text{det}(#1)}", 1], "I": "{\\Mat{I}}", "Skew": ["{\\left(#1\\right)^{\\times}}", 1], "Min": ["\\text{min}(#1, #2)", 2], "Max": ["\\text{max}(#1, #2)", 2], "argmin": "\\mathop{\\mathrm{argmin}", "Argmin": ["\\underset{#1}{\\text{argmin }}", 1], "transpose": "T", "Transpose": ["{#1^{\\transpose}}", 1], "Inv": ["{#1^{-1}}", 1], "Trace": ["\\text{tr}(#1)", 1], "Rank": ["\\text{rank}(#1)", 1], "E": ["\\mathbb{E}\\left[#1\\right]", 1], "Bigslant": ["{\\left#1/#2\\right}", 2], "cost": "J", "error": "{\\Vec{e}}", "SO": ["\\text{SO}(#1)", 1], "so": ["\\mathfrak{so}(#1)", 1], "jac": "\\text{J}", "RV": ["\\mathbf{#1}", 1, ""], "covar": "\\mathbf{\\Sigma}", "frame": "{\\mathcal{F}}", "rot": "{\\Mat{C}}", "trans": "{\\Vec{r}}", "quat": "{{\\Vec{q}}}", "tf": "{\\Mat{T}}", "pt": "{\\Vec{r}}", "Rot": ["{\\rot_{#1#2}}", 2], "Trans": ["{\\trans_{#1#2}}", 2], "Quat": ["{\\quat_{#1#2}}", 2], "Tf": ["{\\tf_{#1#2}}", 2], "Pt": ["{\\pt_{#1#2}}", 2], "state": "{\\Vec{x}}", "pos": "{\\Vec{r}}", "vel": "{\\Vec{v}}", "acc": "{\\Vec{a}}", "dalpha": "{\\delta\\boldsymbol{\\alpha}}", "dbeta": "{\\delta\\boldsymbol{\\beta}}", "dgamma": "{\\delta\\boldsymbol{\\gamma}}", "dtheta": "{\\delta\\boldsymbol{\\theta}}", "dotdalpha": "{\\delta\\dot{\\boldsymbol{\\alpha}}}", "dotdbeta": "{\\delta\\dot{\\boldsymbol{\\beta}}}", "dotdgamma": "{\\delta\\dot{\\boldsymbol{\\gamma}}}", "dotdtheta": "{\\delta\\dot{\\boldsymbol{\\theta}}}", "dPos": "{\\dot{\\Vec{r}}}", "dVel": "{\\dot{\\Vec{v}}}", "angvel": "{\\boldsymbol{\\omega}}", "gravity": "{\\Vec{g}_{W}}", "noise": "{\\Vec{n}}", "bias": "{\\Vec{b}}", "u": "{\\Vec{u}}", "gyr": "{\\angvel}", "gyrMeas": "{\\angvel_{m}}", "gyrNoise": "{\\noise_{\\omega}}", "gyrBias": "{\\bias_{\\omega}}", "gyrBiasNoise": "{\\noise_{\\bias_{\\omega}}}", "accMeas": "{\\acc_{m}}", "accNoise": "{\\noise_{a}}", "accBias": "{\\bias_{a}}", "accBiasNoise": "{\\noise_{\\bias_{a}}}"}}, "packages": ["base", "ams", "noerrors", "noundefined"], "loader": {"load": ["[tex]/ams", "[tex]/noerrors", "[tex]/noundefined"]}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Computer Vision Fundamentals" href="../cv/fundamental.html" />
    <link rel="prev" title="Bayes Theorem" href="bayes.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="pearson-s-chi-squared-test">
<h1>Pearson’s Chi-Squared Test<a class="headerlink" href="#pearson-s-chi-squared-test" title="Permalink to this headline">¶</a></h1>
<p>Pearson’s chi-squared test <span class="math notranslate nohighlight">\(\chi^2\)</span> is a statistical test applied to sets
of <em>categorial data</em> to quantify the likelihood that the observed difference
between measured and predicted arose by chance. The test is used to assess
three types of comparisons:</p>
<ul class="simple">
<li><p><strong>Goodness of fit</strong>: checks whether the observed frequency distribution
matches the theoretical distribution.</p></li>
<li><p><strong>Homogeneity</strong>: compares the distribution of counts for two or more groups
using the same categorical variable.</p></li>
<li><p><strong>Independence</strong>: checks whether the unparied observations on two variables,
expressed in a contingency table, are independent of each other.</p></li>
</ul>
<div class="section" id="goodness-of-fit">
<h2>Goodness of Fit<a class="headerlink" href="#goodness-of-fit" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}\chi^2 &amp;= \sum^{n}_{i=1} \dfrac{(O_i - E_i)^2}{E_i} \\
       &amp;= N \sum^{n}_{i=1} \dfrac{(O_i / N - p_i)^2}{p_i}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\chi^2\)</span> is Pearson’s cumulative test statistic, <span class="math notranslate nohighlight">\(O_i\)</span> is the
number of observations of type <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(N\)</span> is the total number of
observations, <span class="math notranslate nohighlight">\(E_i = N p_i\)</span> is the expected (theoretical) count of type
<span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(n\)</span> is the number of cells in the table.</p>
<p>Once the chi-squared test statistic is calculated, the <span class="math notranslate nohighlight">\(p\)</span>-value is
obtained by comparing the value of the statistic to a chi-squared distribution.
The number of degrees of freedom is equal to the number of cells <span class="math notranslate nohighlight">\(n\)</span>,
minus the reduction in degrees of freedom, <span class="math notranslate nohighlight">\(p\)</span>.</p>
<div class="section" id="example-fairness-of-dice">
<h3>Example: Fairness of dice<a class="headerlink" href="#example-fairness-of-dice" title="Permalink to this headline">¶</a></h3>
<p>A 6-sided die is thrown 60 times. The number of times it lands with 1, 2, 3, 4,
5 and 6 face up is 5, 8, 9, 8, 20 and 20, respectively. Is the die biased,
according to the Pearson’s chi-squared test at a significance level of 95%,
and, or 99%?</p>
<p>In this example <span class="math notranslate nohighlight">\(n = 6\)</span> as there are 6 possible outcomes, 1 to 6. The
null hypothesis is that the die is unbaised, hence each dice number is expected
to occur the same number of times, in this case, <span class="math notranslate nohighlight">\(60 / n = 10\)</span>. The
outcomes can be tabulated as follows:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 9%" />
<col style="width: 12%" />
<col style="width: 12%" />
<col style="width: 17%" />
<col style="width: 20%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(i\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(O_i\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(E_i\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(O_i - E_i\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\((O_i - E_i)^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\dfrac{(O_i - E_i)^2}{E_i}\)</span></p></td>
</tr>
<tr class="row-even"><td rowspan="2"><p>1</p></td>
<td rowspan="2"><p>5</p></td>
<td rowspan="2"><p>10</p></td>
<td rowspan="2"><p>5</p></td>
<td rowspan="2"><p>25</p></td>
<td rowspan="2"><p>2.5</p></td>
</tr>
<tr class="row-odd"></tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>8</p></td>
<td><p>10</p></td>
<td><p>2</p></td>
<td><p>4</p></td>
<td><p>0.4</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>9</p></td>
<td><p>10</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>8</p></td>
<td><p>10</p></td>
<td><p>2</p></td>
<td><p>4</p></td>
<td><p>0.4</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>10</p></td>
<td><p>10</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>20</p></td>
<td><p>10</p></td>
<td><p>10</p></td>
<td><p>100</p></td>
<td><p>10</p></td>
</tr>
</tbody>
</table>
<p>The number of degrees of freedom is <span class="math notranslate nohighlight">\(n - 1 = 5\)</span>. The Upper tail critical
values of chi-square distribution gives a critical value of 11.070 at 95%
significance level:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 6%" />
<col style="width: 47%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 10%" />
<col style="width: 9%" />
<col style="width: 11%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Dof</p></td>
<td><p>Probability less than the critical value</p></td>
<td><p><em>0.90</em></p></td>
<td><p><em>0.95</em></p></td>
<td><p><em>0.975</em></p></td>
<td><p><em>0.99</em></p></td>
<td><p><em>0.999</em></p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td></td>
<td><p>9.236</p></td>
<td><p>11.070</p></td>
<td><p>12.833</p></td>
<td><p>15.086</p></td>
<td><p>20.515</p></td>
</tr>
</tbody>
</table>
<p>As the chi-squared statistic of 13.4 exceeds this critical value, the null
hypothesis is rejected and conclude that the die is biased at 95% significance
level. At 99% significance level, the critical value is 15.086. As the
chi-squared statistic does not exceed it, the null hypothesis is not rejected
and thus conclude that there is insufficient evidence to show that the die is
biased at 99% significance level.</p>
</div>
<div class="section" id="problems-with-pearson-s-chi-squared-test">
<h3>Problems with Pearson’s Chi-Squared Test<a class="headerlink" href="#problems-with-pearson-s-chi-squared-test" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>The degrees of freedom can only be estimated for <em>linear
models</em>. It is non-trivial or near impossible to estimate the degrees of
freedom for a <em>non-linear model</em>.</p></li>
<li><p>The value of chi-squared itself is subject to noise in the data, as
such the value is uncertain.</p></li>
</ul>
<p>Knowing the degrees of freedom of the model in question is required for
chi-squared test. For <span class="math notranslate nohighlight">\(N\)</span> data points and <span class="math notranslate nohighlight">\(P\)</span> parameters, a naive
guess is that the number of degrees of freedom is <span class="math notranslate nohighlight">\(N - P\)</span>. This, however,
as will be demonstrated is not always the case.</p>
<p>The chi-squared test statistic, <span class="math notranslate nohighlight">\(\chi^2\)</span>, for continuous data is defined
as,</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum^{N}_{n = 1}
  \left( \dfrac{(y_n - f(x_n, \theta))}{\sigma_n} \right)^2\]</div>
<p>which is equivalent to maximizing the liklihood function. For a linear model,
the chi-squared statistic, <span class="math notranslate nohighlight">\(\chi^2\)</span> can be written in matrix form as,</p>
<div class="math notranslate nohighlight">
\[\chi^2 =
  (\Vec{y} - \Mat{X} \boldsymbol{\theta})^{\transpose}
  \Mat{\Sigma}^{-1}
  (\Vec{y} - \Mat{X} \boldsymbol{\theta}) .\]</div>
<p>Rearranging in terms of the model parameters, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>,
gives,</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{\theta} =
  (\Mat{X}^{\transpose} \Mat{\Sigma}^{-1} \Mat{X})^{-1}
  \Mat{X}^{\transpose} \Mat{\Sigma}^{-1} \Vec{y} .\]</div>
<p>Finally, the prediction, <span class="math notranslate nohighlight">\(\hat{\Vec{y}}\)</span>, of the measurements,
<span class="math notranslate nohighlight">\(\Vec{y}\)</span>, can be obtained by multiplying the design matrix,
<span class="math notranslate nohighlight">\(\Mat{X}\)</span>, with the model parameters, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>, and
further simplified to give us,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
  \hat{\Vec{y}}
    &amp;= \Mat{X} \boldsymbol{\theta} \\
    &amp;= \Mat{X} (\Transpose{\Mat{X}} \Mat{\Sigma}^{-1} \Mat{X})^{-1}
       \Transpose{\Mat{X}} \Mat{\Sigma}^{-1} \Vec{y} \\
    &amp;= \Mat{H} \Vec{y}
\end{align}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Mat{H}\)</span> is an <cite>N times N</cite> matrix, sometimes called the “hat
matrix” because it translates the measurement data, <span class="math notranslate nohighlight">\(\Vec{y}\)</span>, into a
model prediction, <span class="math notranslate nohighlight">\(\hat{\Vec{y}}\)</span>. The number of <em>effecitve</em> model
parameters, <span class="math notranslate nohighlight">\({P}_{\text{eff}}\)</span>, is then given by the trace of
<span class="math notranslate nohighlight">\(\Mat{H}\)</span>,</p>
<div class="math notranslate nohighlight">
\[P_{\text{eff}} = \Trace{\Mat{H}} = \sum^{N}_{n = 1} H_{nn} = \Rank{\Mat{X}} .\]</div>
<p>which also equals the rank of the design matrix <span class="math notranslate nohighlight">\(\Mat{X}\)</span>. And so,
<span class="math notranslate nohighlight">\(P_{\text{eff}} \leq P\)</span>, where the equality holds if and only if the
design matrix <span class="math notranslate nohighlight">\(\Mat{X}\)</span> has full rank. Consequently, for linear models
the number of degrees of freedom is,</p>
<div class="math notranslate nohighlight">
\[K = N - P_{\text{eff}} \geq N - P\]</div>
<p>For nonlinear models, the degrees of freedom is not as straight forward.</p>
<p><strong>Example 1</strong></p>
<p>Let us consider a nonlinear model with three free parameters, <span class="math notranslate nohighlight">\(A\)</span>,
<span class="math notranslate nohighlight">\(B\)</span>, and <span class="math notranslate nohighlight">\(C\)</span>,</p>
<div class="math notranslate nohighlight">
\[f(x) = A \cos(Bx + C) .\]</div>
<p>If we are given a set of <span class="math notranslate nohighlight">\(N\)</span> measurement <span class="math notranslate nohighlight">\((x_n, y_n, \sigma_n)\)</span>
such that no two data points have identical <span class="math notranslate nohighlight">\(x_n\)</span>, then the model
<span class="math notranslate nohighlight">\(f(x)\)</span> is capable of fitting any such data set perfectly. The way this
works is by increasing the “frequency” <span class="math notranslate nohighlight">\(B\)</span> such that <span class="math notranslate nohighlight">\(f(x)\)</span> can
change on arbitrarily short scales. As <span class="math notranslate nohighlight">\(f(x)\)</span> provides a perfect fit in
this case, <span class="math notranslate nohighlight">\(\chi^2\)</span> is equal to zero for all possible noise realizations
of the data. Evidently, this three-parameter model has infinite flexibility (if
there are no priors) and <span class="math notranslate nohighlight">\(K = N - P\)</span> is a poor estimate of the number of
degrees of freedom, which actually is <span class="math notranslate nohighlight">\(K = 0\)</span>.</p>
<p><strong>Example 2</strong></p>
<p>To build upon the first example, three additional model parameters, <cite>D</cite>, <cite>E</cite>
and <cite>F</cite> are added,</p>
<div class="math notranslate nohighlight">
\[f(x) = A \cos(Bx + C) + D \cos(Ex + F) .\]</div>
<p>If the fit parameter <span class="math notranslate nohighlight">\(D\)</span> becomes small such that <span class="math notranslate nohighlight">\(|D| \leq |A|\)</span>,
the second component cannot influence the fit anymore and the two model
parameters <span class="math notranslate nohighlight">\(E\)</span> and <span class="math notranslate nohighlight">\(F\)</span> are “lost”. In simple words: This model may
change its flexibility during the fitting procedure.</p>
<p>Hence, for nonlinear models, <span class="math notranslate nohighlight">\(K\)</span> may not even be constant. Of course,
these two examples do not verify the claim that always <span class="math notranslate nohighlight">\(K \neq N - P\)</span> for
nonlinear models.  However, acting as counter-examples, they clearly falsify
the claim that <span class="math notranslate nohighlight">\(K = N - P\)</span> is always true for nonlinear models.</p>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">proto</a></h1>










<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../linalg/rank.html">Rank</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/trace.html">Trace</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/cond.html">Condition Number</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/inv.html">Inverting a Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/lu.html">LU Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/chol.html">Cholesky Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/qr.html">QR Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/svd.html">SVD Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/schurs.html">Shurs’ Complement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/ssole.html">Solving System of Linear Equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/lls.html">Linear Least Squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linalg/nlls.html">Non-linear Least Squares</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Statistics</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mean.html">Mean</a></li>
<li class="toctree-l1"><a class="reference internal" href="variance.html">Variance</a></li>
<li class="toctree-l1"><a class="reference internal" href="stddev.html">Standard Deviation</a></li>
<li class="toctree-l1"><a class="reference internal" href="stderr.html">Standard Error</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes.html">Bayes Theorem</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Pearson’s Chi-Squared Test</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#goodness-of-fit">Goodness of Fit</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Vision</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cv/fundamental.html">Computer Vision Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/pinhole.html">Pinhole Camera Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/radtan.html">Radial-Tangential Distortion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/equi.html">Equi-Distant Distortion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/illum_invar.html">Illumination Invariant Transform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/optical_flow.html">Optical Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/twoview.html">Two-View Geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/triangulation.html">Triangulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/ba.html">Bundle Adjustment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cv/feature_tracking.html">Feature Tracking</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">State Estimation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../se/euler.html">Euler Angles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../se/quaternions.html">Quaternions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../se/diff_calc.html">Differential Calculus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../se/covar_recovery.html">Covariance Recovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../se/shannon.html">Shannon Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../se/imu.html">IMU Preintegration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../se/gauge.html">Gauge Freedom</a></li>
<li class="toctree-l1"><a class="reference internal" href="../se/marginalization.html">Marginalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../se/eskf.html">Error-State Kalman Filter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MAV</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mav/mpc.html">Outerloop Linear MPC for MAV</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="bayes.html" title="previous chapter">Bayes Theorem</a></li>
      <li>Next: <a href="../cv/fundamental.html" title="next chapter">Computer Vision Fundamentals</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Chris Choi.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.4.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/stats/chisq_test.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/chutsu/proto" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>