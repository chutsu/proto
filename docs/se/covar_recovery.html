<h1>Covariance Recovery</h1>

The Gauss-Newton system is:
<equation>
    \Mat{H} \Delta{\Vec{x}} = \Vec{g}
</equation>
where the hessian $\Mat{H}$ can be decomposed into $\Mat{R}^{\transpose}
\Mat{R}$ using either Cholesky or QR factorization. The objective is to recover
the marginal covariance matrix $\covar = \Mat{H}^{-1}$ without inverting
$\Mat{H}$, since it is expensive and numerically unstable if it is not well
conditioned.

Let us write,
<equation>
  (\Mat{R}^{\transpose} \Mat{R})^{-1}
		&= \covar
		= \begin{bmatrix}
			\covar_{1} &
			\covar_{2} &
			\dots &
			\covar_{n}
		\end{bmatrix} \\
		(\Mat{R}^{\transpose} \Mat{R})(\Mat{R}^{\transpose} \Mat{R})^{-1}
		&= \I \\
			(\Mat{R}^{\transpose} \Mat{R}) \covar
		&= \I \\
			\Mat{R} \covar &= (\Mat{R}^{\transpose})^{-1}.
</equation>
Note that if we focus on the last column of $\covar$ and last diagonal element
in $(\Mat{R}^{\transpose})^{-1}$, we can rewrite $\Mat{R} \covar =
(\Mat{R}^{\transpose})^{-1}$ as
<equation>
\underbrace{
	\begin{bmatrix}
		r_{11} & r_{12} & \cdots & r_{1n} \\
		0 & r_{22} & \cdots & r_{2n} \\
		\vdots & \vdots & \ddots & \vdots \\
		0 & 0 & \cdots & r_{nn} \\
	\end{bmatrix}
}_{\Mat{R}}
\underbrace{
	\begin{bmatrix}
		\sigma_{1,n} \\
		\sigma_{2,n} \\
		\vdots \\
		\sigma_{n,n}
	\end{bmatrix}
}_{\covar_{n}}
=
\underbrace{
	\begin{bmatrix}
		0 \\
		0 \\
		\vdots \\
		1 / r_{nn}
	\end{bmatrix}
}_{\{(\Mat{R}^{\transpose})^{-1}\}_{ii}}
</equation>
and write out the matrix notation,
<equation>
	&r_{nn} \sigma_{n,n} = 1 / r_{nn} \\
	&\quad\quad\quad\quad\quad\quad\vdots \\
	&r_{2,2} \sigma_{2,n} + r_{2,3} \sigma_{3,n}
      + \dots + r_{2,n} \sigma_{n,n} = 0 \\
	&r_{1,1} \sigma_{1,n} + r_{1,2} \sigma_{2,n}
      + \dots + r_{1,n} \sigma_{n,n} = 0 \\
</equation>
and rearrange to solve for $\sigma_{i,n}$ in $\covar_{n}$,
<equation>
	&\sigma_{n,n} = (r_{nn})^{-2} \\
	&\quad\quad\quad\quad\quad\quad\vdots \\
	&\sigma_{2,n} = (-r_{2,3} \sigma_{3,n}
                   - \dots - r_{2,n} \sigma_{n,n}) / r_{2,2}  \\
	&\sigma_{1,n} = (-r_{1,2} \sigma_{2,n}
                   - \dots - r_{1,n} \sigma_{n,n}) / r_{1,1}
</equation>
or more generally,
<equation>
	&\sigma_{n,n} = (r_{nn})^{-2} \\
	&\sigma_{i,n} = \dfrac{-\sum_{j=i+1}^{1} r_{ij} \sigma_{j,n}}{r_{ii}}
	\quad
	\text{where} \; i = n - 1, \cdots, 1
</equation>
which is essentially performing back-substition.
</p>

<hr><!------------------------------------------------------------------------!>

<!-- <equation> -->
<!-- \underbrace{ -->
<!-- 	\begin{bmatrix} -->
<!-- 		r_{11} &#38; r_{12} &#38; \cdots &#38; r_{1n} \\ -->
<!-- 		0 &#38; r_{22} &#38; \cdots &#38; r_{2n} \\ -->
<!-- 		\vdots &#38; \vdots &#38; \ddots &#38; \vdots \\ -->
<!-- 		0 &#38; 0 &#38; \cdots &#38; r_{nn} \\ -->
<!-- 	\end{bmatrix} -->
<!-- }_{\Mat{R}} -->
<!-- \underbrace{ -->
<!-- 	\begin{bmatrix} -->
<!--     \sigma_{1,1} &#38; \sigma_{1,2} &#38; \dots &#38; \sigma_{1,n} \\ -->
<!--     \sigma_{2,1} &#38; \sigma_{2,2} &#38; \dots &#38; \sigma_{2,n} \\ -->
<!-- 		\vdots &#38; \vdots &#38; \vdots &#38; \vdots \\ -->
<!--     \sigma_{n,1} &#38; \sigma_{n,2} &#38; \dots &#38; \sigma_{n,n} \\ -->
<!-- 	\end{bmatrix} -->
<!-- }_{\covar} -->
<!-- = -->
<!-- \underbrace{ -->
<!-- \begin{bmatrix} -->
<!--   r_{11} &#38; 0 &#38; \dots &#38; 0 \\ -->
<!--   r_{21} &#38; r_{22} &#38; \dots &#38; 0 \\ -->
<!--   \vdots &#38; \vdots &#38; \ddots &#38; \vdots \\ -->
<!--   r_{m1} &#38; r_{m2} &#38; \dots &#38; r_{nn} -->
<!-- \end{bmatrix} -->
<!-- }_{(\Mat{R}^{\transpose})^{&#45;1}} -->
<!-- </equation> -->
<!-- and write out the matrix notation, -->
<!-- <equation> -->
<!-- 	&#38;r_{nn} \sigma_{n,n} = 1 / r_{nn} \\ -->
<!-- 	&#38;\quad\quad\quad\quad\quad\quad\vdots \\ -->
<!-- 	&#38;r_{2,2} \sigma_{2,n} + r_{2,3} \sigma_{3,n} -->
<!--       + \dots + r_{2,n} \sigma_{n,n} = 0 \\ -->
<!-- 	&#38;r_{1,1} \sigma_{1,n} + r_{1,2} \sigma_{2,n} -->
<!--       + \dots + r_{1,n} \sigma_{n,n} = 0 \\ -->
<!-- </equation> -->

<equation>
	\begin{bmatrix}
		r_{11} & r_{12} & r_{13} & r_{14} \\
    0 & r_{22} & r_{23} & r_{24} \\
    0 & 0 & r_{33} & r_{34} \\
    0 & 0 & 0 & r_{44}
	\end{bmatrix}
	\begin{bmatrix}
		\sigma_{11} & \sigma_{12} & \sigma_{13} & \sigma_{14} \\
    \sigma_{21} & \sigma_{22} & \sigma_{23} & \sigma_{24} \\
    \sigma_{31} & \sigma_{32} & \sigma_{33} & \sigma_{34} \\
    \sigma_{41} & \sigma_{42} & \sigma_{43} & \sigma_{44}
	\end{bmatrix}
  =
  \begin{bmatrix}
    z_{11} & 0 & 0 & 0 \\
    z_{21} & z_{22} & 0 & 0 \\
    z_{31} & z_{32} & z_{33} & 0 \\
    z_{41} & z_{42} & z_{43} & z_{44}
  \end{bmatrix}
</equation>

<h3>1st Column</h3>
<equation>
r_{11} \sigma_{11} + r_{12} \sigma_{21} + r_{13} \sigma_{31} + r_{14} \sigma_{41} &= z_{11} \\
</equation>

<equation>
\sigma_{11} &= (z_{11} -r_{12} \sigma_{21} - r_{13} \sigma_{31} - r_{14} \sigma_{41}) / r_{11} \\
</equation>

<h3>2nd Column</h3>
<equation>
r_{11} \sigma_{12} + r_{12} \sigma_{22} + r_{13} \sigma_{32} + r_{14} \sigma_{42} &= 0 \\
r_{22} \sigma_{22} + r_{23} \sigma_{32} + r_{24} \sigma_{42} &= z_{22} \\
</equation>

<equation>
\sigma_{12} &= (-r_{12} \sigma_{22} - r_{13} \sigma_{32} - r_{14} \sigma_{42}) / r_{11} \\
\sigma_{22} &= (z_{22} -r_{23} \sigma_{32} - r_{24} \sigma_{42}) / r_{22} \\
</equation>

<h3>3rd Column</h3>
<equation>
r_{11} \sigma_{13} + r_{12} \sigma_{23} + r_{13} \sigma_{33} + r_{14} \sigma_{43} &= 0 \\
r_{22} \sigma_{23} + r_{23} \sigma_{33} + r_{24} \sigma_{43} &= 0 \\
r_{33} \sigma_{33} + r_{34} \sigma_{43} &= z_{33} \\
</equation>


<equation>
\sigma_{13} &= (-r_{12} \sigma_{23} - r_{13} \sigma_{33} - r_{14} \sigma_{43}) / r_{11} \\
\sigma_{23} &= (-r_{23} \sigma_{33} - r_{24} \sigma_{43}) / r_{22} \\
\sigma_{33} &= (z_{33} - r_{34} \sigma_{43}) / r_{33}
</equation>


<h3>4th Column</h3>
<equation>
r_{11} \sigma_{14} + r_{12} \sigma_{24} + r_{13} \sigma_{34} + r_{14} \sigma_{44} &= 0 \\
r_{22} \sigma_{24} + r_{23} \sigma_{34} + r_{24} \sigma_{44} &= 0 \\
r_{33} \sigma_{34} + r_{34} \sigma_{44} &= 0 \\
r_{44} \sigma_{44} &= z_{44}
</equation>

<equation>
\sigma_{14} &= (-r_{12} \sigma_{24} - r_{13} \sigma_{34} - r_{14} \sigma_{44}) / r_{11} \\
\sigma_{24} &= (-r_{23} \sigma_{34} + r_{24} \sigma_{44}) / r_{22}  \\
\sigma_{34} &= (-r_{34} \sigma_{44}) / r_{33} \\
\sigma_{44} &= z_{44} / r_{44}
</equation>


<h3>Diagonals</h3>

<equation>
\sigma_{11} &= (z_{11} -r_{12} \sigma_{21} - r_{13} \sigma_{31} - r_{14} \sigma_{41}) / r_{11} \\
\sigma_{22} &= (z_{22} -r_{23} \sigma_{32} - r_{24} \sigma_{42}) / r_{22} \\
\sigma_{33} &= (z_{33} - r_{34} \sigma_{43}) / r_{33} \\
\sigma_{44} &= z_{44} / r_{44}
</equation>

<equation>
\sigma_{ii} = \dfrac{1}{r_{ii}} \left(z_{ii} - \sum_{j=i+1}^{n} r_{i,j} \sigma_{j,i}\right) \\
</equation>

Since we know that the inverse of the diagonals are its reciprocal, $z_{ii}$
can be written as $\frac{1}{r_{ii}}$ giving us the general formula for the
diagonals of $\covar$ as,
<equation>
  \boxed{
    \sigma_{ii} = \dfrac{1}{r_{ii}} \left(
      \dfrac{1}{r_{ii}} - \sum_{j=i+1}^{n} r_{i,j} \sigma_{j,i}
    \right)
  }
</equation>


<h3>Off-Diagonals</h3>

<equation>
\sigma_{12} &= (-r_{12} \sigma_{22} - r_{13} \sigma_{32} - r_{14} \sigma_{42}) / r_{11} \\
\sigma_{13} &= (-r_{12} \sigma_{23} - r_{13} \sigma_{33} - r_{14} \sigma_{43}) / r_{11} \\
\sigma_{14} &= (-r_{12} \sigma_{24} - r_{13} \sigma_{34} - r_{14} \sigma_{44}) / r_{11} \\ \\
\sigma_{23} &= (-r_{23} \sigma_{33} - r_{24} \sigma_{43}) / r_{22} \\
\sigma_{24} &= (-r_{23} \sigma_{34} + r_{24} \sigma_{44}) / r_{22}  \\ \\
\sigma_{34} &= (-r_{34} \sigma_{44}) / r_{33} \\
</equation>

<equation>
\sigma_{il} = \dfrac{1}{r_{ii}} \left( \sum_{j=l}^{n} r_{i,j} \sigma_{j,l} \right)
</equation>
